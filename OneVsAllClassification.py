# -*- coding: utf-8 -*-
"""
Created on Wed Dec 20 17:10:43 2017

@author: MONIK RAJ
"""
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
from sklearn.linear_model import LogisticRegression
d = loadmat("D:/STUDY - IMPORTANT/COMPUTER/Coursera-Machine Learning -By Andrew Ng/VIII. Neural Networks Representation (Week 4)/ex3/ex3/ex3data1.mat")

X = d['X']
Y = d['y']
m = [  85,   70,  230,  142,  419,  473,  374,  482,   38,  254,  260,
        375,  395,  450,   91,  285,  179,  330,   86,  358,  363,  256,
        146,  464,   11,  478,  255,  158,  169,  340,  287,   26,   79,
        387,  454,   30,  446,  281,  412,  237,  177,  393,   56,  160,
        155,  488,  225,  105,  451,  300,  686,  691,  661,  558,  672,
        693,  875,  709,  656,  963,  761,  563,  803,  517,  862,  533,
        725,  736,  606,  948,  966,  788,  813,  607,  696,  801,  564,
        555,  651,  988,  729,  794,  843,  739,  962,  865,  884,  545,
        720,  826,  772,  719,  798,  669,  546,  976,  928,  776,  532,
        839, 1468, 1389, 1192, 1375, 1011, 1027, 1117, 1277, 1233, 1477,
       1162, 1163, 1281, 1155, 1412, 1069, 1379, 1094, 1478, 1248, 1461,
       1006, 1410, 1061, 1256, 1460, 1426, 1240, 1049, 1376, 1306, 1210,
       1268, 1252, 1174, 1024, 1344, 1131, 1494, 1403, 1416, 1000, 1156,
       1332, 1066, 1102, 1226, 1314, 1122, 1231, 1743, 1889, 1690, 1764,
       1785, 1510, 1649, 1903, 1500, 1841, 1680, 1622, 1701, 1775, 1765,
       1804, 1662, 1905, 1610, 1712, 1722, 1564, 1937, 1876, 1931, 1695,
       1567, 1836, 1773, 1551, 1552, 1999, 1759, 1549, 1984, 1890, 1922,
       1635, 1770, 1794, 1654, 1824, 1780, 1615, 1529, 1944, 1550, 1656,
       1617, 1736, 2499, 2297, 2441, 2269, 2149, 2491, 2291, 2489, 2361,
       2010, 2392, 2014, 2264, 2209, 2065, 2369, 2422, 2355, 2287, 2024,
       2018, 2353, 2458, 2120, 2063, 2430, 2469, 2080, 2294, 2488, 2142,
       2339, 2054, 2214, 2196, 2105, 2302, 2107, 2436, 2364, 2202, 2246,
       2468, 2343, 2007, 2111, 2096, 2067, 2322, 2190, 2938, 2572, 2643,
       2795, 2655, 2630, 2855, 2634, 2582, 2533, 2810, 2792, 2846, 2959,
       2800, 2637, 2612, 2738, 2871, 2813, 2559, 2598, 2764, 2839, 2919,
       2925, 2622, 2967, 2577, 2546, 2506, 2514, 2796, 2983, 2679, 2999,
       2614, 2837, 2632, 2717, 2785, 2699, 2747, 2987, 2734, 2790, 2780,
       2741, 2885, 2531, 3414, 3053, 3419, 3337, 3001, 3068, 3204, 3457,
       3295, 3226, 3205, 3304, 3130, 3119, 3492, 3067, 3012, 3057, 3086,
       3488, 3229, 3084, 3422, 3381, 3270, 3142, 3395, 3342, 3379, 3291,
       3056, 3069, 3203, 3448, 3160, 3305, 3030, 3282, 3141, 3014, 3362,
       3227, 3441, 3413, 3061, 3065, 3287, 3296, 3076, 3233, 3614, 3803,
       3507, 3612, 3656, 3745, 3849, 3533, 3661, 3773, 3589, 3628, 3983,
       3748, 3561, 3560, 3545, 3699, 3827, 3831, 3958, 3525, 3852, 3791,
       3607, 3500, 3907, 3528, 3841, 3688, 3755, 3542, 3935, 3964, 3670,
       3514, 3911, 3592, 3952, 3725, 3531, 3552, 3819, 3896, 3618, 3720,
       3970, 3828, 3535, 3756, 4069, 4206, 4264, 4187, 4353, 4026, 4383,
       4334, 4097, 4497, 4129, 4436, 4189, 4345, 4064, 4272, 4400, 4270,
       4447, 4407, 4469, 4077, 4060, 4017, 4068, 4491, 4144, 4119, 4287,
       4100, 4031, 4194, 4235, 4318, 4062, 4034, 4493, 4252, 4431, 4361,
       4104, 4332, 4387, 4342, 4238, 4101, 4244, 4393, 4111, 4268, 4988,
       4506, 4953, 4881, 4906, 4767, 4870, 4794, 4753, 4942, 4584, 4826,
       4513, 4801, 4963, 4956, 4917, 4571, 4966, 4842, 4856, 4647, 4673,
       4640, 4938, 4682, 4765, 4604, 4958, 4857, 4746, 4862, 4858, 4819,
       4901, 4839, 4784, 4627, 4922, 4914, 4558, 4594, 4681, 4534, 4600,
       4886, 4572, 4618, 4797, 4758]

Xt = []
Yt = []
for i in range(0,len(m)):
    Xt.append(X[m[i]])
    Yt.append(Y[m[i]])
#X = np.array(Xt)
#Y = np.array(Yt).reshape(500,)
#X = Xt
#Y = Yt
'''
q = X.reshape(5000,20,20)
for i in range(0,5000):
    q[i] = q[i].T
m=np.random.choice(range(5000),100,replace=False)
n = m.tolist()
M = []
for i in range(0,10):
    w = np.concatenate((q[n[i*10+0]],q[n[i*10+1]],q[n[i*10+2]],q[n[i*10+3]],q[n[i*10+4]],q[n[i*10+5]],q[n[i*10+6]],q[n[i*10+7]],q[n[i*10+8]],q[n[i*10+9]]), axis =1)
    M.append(w)    
N = np.concatenate((M[0],M[1],M[2],M[3],M[4],M[5],M[6],M[7],M[8],M[9]),axis=0)
N = (N-N.min())/(N.max()-N.min()) * 255 
imgplot = plt.imshow(N)
'''
Y1 = np.zeros((5000,))
Y2 = np.zeros((5000,))
Y3 = np.zeros((5000,))
Y4 = np.zeros((5000,))
Y5 = np.zeros((5000,))
Y6 = np.zeros((5000,))
Y7 = np.zeros((5000,))
Y8 = np.zeros((5000,))
Y9 = np.zeros((5000,))
Y10 = np.zeros((5000,))
for i in range(0,len(Y)):
    if Y[i]==1:
        Y1[i]=1
    if Y[i]==2:
        Y2[i]=1
    if Y[i]==3:
        Y3[i]=1
    if Y[i]==4:
        Y4[i]=1
    if Y[i]==5:
        Y5[i]=1
    if Y[i]==6:
        Y6[i]=1
    if Y[i]==7:
        Y7[i]=1
    if Y[i]==8:
        Y8[i]=1
    if Y[i]==9:
        Y9[i]=1
    if Y[i]==10:
        Y10[i]=1

Yset = [Y1,Y2,Y3,Y4,Y5,Y6,Y7,Y8,Y9,Y10]
lr = LogisticRegression()
lr.fit(X,Yset[0])
m = lr.predict_proba(X)[:,1]
m = m.reshape(5000,1)
for i in range(1,10):
    lr.fit(X,Yset[i])
    a = lr.predict_proba(X)[:,1]
    a = a.reshape(5000,1)
    m = np.hstack((m,a))
f = np.argmax(m,axis=1)
Yhypo=f+1
Yhypo = Yhypo.reshape(5000,1)
E = Yhypo - Y
ed = np.nonzero(E)[0].shape[0]
acc = ((5000-ed)/5000)*100
print("Accuracy : " + str(acc))
'''
def multiClass(lr,X,Yset,Xtest):
    EachClassProb = []
    for i in range(0,10):
        lr.fit(X,Yset[i])
        b = lr.predict_proba(Xtest.reshape(1,-1))[0][1]
        EachClassProb.append(b)
    Hypo = EachClassProb.index(max(EachClassProb))+1
    return Hypo

Yhypo = []

for i in range(0,len(Y)):
    Yhypo.append(multiClass(lr,X,Yset,X[i]))
    print(i+1)
Yhypo = np.array(Yhypo)
'''
